{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\n",
    "#    \"text.usetex\": True,\n",
    "#    \"font.family\": \"mathptmx\",\n",
    "    \"font.size\": 14\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_label(config) -> str:\n",
    "    return config[0] + ', ' + (\n",
    "        'constr.' if config[1] else 'unconstr.'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../results/thesis/perf_KBPGP_vs_GPL.csv')\n",
    "\n",
    "# remove wave power.\n",
    "df = df[df.Problem != 'Wave power']\n",
    "\n",
    "for r2_col in ['Train-R2', 'Test-R2', 'Extra-R2']:\n",
    "    df.loc[df[r2_col] < 0.0, r2_col] = 0.0\n",
    "    df[r2_col] = df[r2_col].fillna(0.0)\n",
    "\n",
    "\n",
    "def plot_subgroup(i, config, group, axs):\n",
    "    # feasibility ratio\n",
    "        ax = axs[0][i]\n",
    "\n",
    "        if i == 0: ax.set_ylabel('Fea. ratio')\n",
    "        ax.set_xlabel(get_config_label(config))\n",
    "        ax.xaxis.set_label_position('top')\n",
    "        ax.xaxis.labelpad = 1\n",
    "        ax.set_ylim(bottom=0.0, top=1.0)\n",
    "        ax.tick_params(direction='in', length=5)\n",
    "        \n",
    "        x_features = ['Train-Fea-Ratio', 'Avg-Train-Fea-Ratio']\n",
    "        x_labels   = ['Best', 'Avg', 'Worst']\n",
    "        group.boxplot(column=x_features, ax=ax)\n",
    "        ax.set_xticklabels(x_labels, rotation=0)\n",
    "\n",
    "        # data fitting.\n",
    "        ax = axs[1][i]\n",
    "\n",
    "        if i == 0: ax.set_ylabel('NMSE')\n",
    "        ax.set_ylim(bottom=0.0, top=1.0)\n",
    "        ax.tick_params(direction='in', length=5)\n",
    "        \n",
    "        x_features = ['Train-R2', 'Test-R2', 'Extra-R2', 'Avg-Train-R2']\n",
    "        x_labels   = ['Train', 'Test', 'Extra', 'Avg']\n",
    "        group.boxplot(column=x_features, ax=ax)\n",
    "        ax.set_xticklabels(x_labels, rotation=0)\n",
    "\n",
    "\n",
    "def plot_group(problem, problem_group):\n",
    "    subgroups = problem_group.groupby(['Data-Config', 'Algo-Config'])\n",
    "    \n",
    "    fig, axs = plt.subplots(2, subgroups.ngroups, figsize=((15/6)*subgroups.ngroups, 4), sharey=True)\n",
    "    fig.suptitle(problem, weight='bold', y=0.0)\n",
    "    \n",
    "    for i, (config, group) in enumerate(subgroups):\n",
    "        plot_subgroup(i, config, group, axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 'Test-NMSE'  # A vs B\n",
    "B = 'Test-Fea-Ratio'\n",
    "\n",
    "A_measure_name = 'NMSE Test'\n",
    "B_measure_name = 'Fea. Test'\n",
    "\n",
    "Algo1 = 'KBP-GP'\n",
    "Algo2 = 'GP-L'\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(11, 12), sharey=True)\n",
    "nproblems = 0\n",
    "problem_labels = []\n",
    "\n",
    "cmap = matplotlib.colormaps.get_cmap('magma')\n",
    "bar_colors = {'nonoise': cmap(0.3), 'noisy': cmap(0.4), 'dataset': cmap(0.0)}\n",
    "problem_prefix = {'nonoise': '', 'noisy': '-N', 'dataset': '-D'}\n",
    "fmt = {'nonoise': 'o', 'noisy': '^', 'dataset': 's'}\n",
    "#fmt = {True: 'o', False: 'x'}\n",
    "i = 0\n",
    "\n",
    "for data_conf in ['nonoise', 'noisy', 'dataset']:\n",
    "\n",
    "    problem_bars = []\n",
    "\n",
    "    for problem, problem_group in df.loc[df['Data-Config'] == data_conf].groupby('Problem'):\n",
    "\n",
    "        bars = {ax_idx: [] for ax_idx in range(4)}\n",
    "\n",
    "        for algo_config, algo_config_group in problem_group.groupby('Algo-Config'):\n",
    "            \n",
    "            for measure in [A, B]:\n",
    "                offset = 0 if measure == A else 2\n",
    "                ax_idx = offset + (0 if algo_config == 'KBP-GP' else 1)\n",
    "                ax = axs[ax_idx]\n",
    "\n",
    "                values = algo_config_group[measure].to_numpy()\n",
    "                values[values < 0.0] = 0.0\n",
    "                median = np.median(values)\n",
    "                l, u = values.min(), values.max()\n",
    "                if l != u:\n",
    "                    l, u = stats.t.interval(0.95, values.size-1, loc=median, scale=stats.sem(values))\n",
    "                l = max(0.0, l)\n",
    "                u = min(1.0, u)\n",
    "\n",
    "                bars[ax_idx] = (median, l, u, data_conf)\n",
    "                #ax.errorbar(median, i, xerr=[[median-l],[u-median]], fmt=fmt[data_conf], color=bar_colors[data_conf], elinewidth=1.5, capsize=6, label=data_conf)\n",
    "\n",
    "        nproblems += 1\n",
    "        if problem.startswith('feynman-'):\n",
    "            problem = problem.removeprefix('feynman-').upper()\n",
    "        problem_label = problem + problem_prefix[data_conf]\n",
    "        problem_bars.append((problem_label, bars))\n",
    "\n",
    "    problem_bars = sorted(problem_bars, reverse=False, key=lambda b: b[1][0][0])\n",
    "    for problem_lbl, bars in problem_bars:\n",
    "        problem_labels.append(problem_lbl)\n",
    "        for ax_idx, (median, l, u, data_conf) in bars.items():\n",
    "            #constr = ax_idx == 1 or ax_idx == 3\n",
    "            #if constr: ax_idx -= 1\n",
    "            axs[ax_idx].errorbar(median, i, xerr=[[median-l],[u-median]], fmt=fmt[data_conf], color=bar_colors[data_conf], elinewidth=1.5, capsize=6, label=data_conf, clip_on=False)\n",
    "            #if not constr: i += 1\n",
    "        i += 1\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_yticks(np.arange(nproblems))\n",
    "    ax.tick_params(direction='in', length=0)\n",
    "    ax.grid(linewidth=0.3)\n",
    "    ax.margins(0.025)\n",
    "    for side in ['top','bottom','left','right']:\n",
    "        ax.spines[side].set_linewidth(0)\n",
    "\n",
    "axs[0].set_xlim([0.0, 1.0])\n",
    "axs[0].set_yticklabels(problem_labels)\n",
    "axs[0].tick_params(axis='y', pad=10)\n",
    "axs[0].set_title(Algo1)\n",
    "axs[0].set_xlabel(A_measure_name)\n",
    "\n",
    "axs[1].set_xlim([0.0, 1.0])\n",
    "axs[1].set_title(Algo2)\n",
    "axs[1].set_xlabel(A_measure_name)\n",
    "\n",
    "axs[2].set_xlim([0.0, 1.0])\n",
    "axs[2].set_title(Algo1)\n",
    "axs[2].set_xlabel(B_measure_name)\n",
    "\n",
    "axs[3].set_xlim([0.0, 1.0])\n",
    "axs[3].set_title(Algo2)\n",
    "axs[3].set_xlabel(B_measure_name)\n",
    "\n",
    "#fig.suptitle('Data and Knowledge Results (95% CI)', weight='bold', y=0.0)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "def legend_without_duplicate_labels(figure):\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    figure.legend(by_label.values(), by_label.keys(), loc='lower center', ncol=3)\n",
    "\n",
    "legend_without_duplicate_labels(fig)\n",
    "\n",
    "plt.gca().set_rasterization_zorder(0)\n",
    "plt.savefig('../figs/thesis/KBP-GP_vs_GP-L_TestAcc.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "problem_name_prefix = {'nonoise': '', 'noisy': '-N', 'dataset': '-D'}\n",
    "header = ['Problem', 'p-value (constr. > unconstr.)', 'p-value (constr. â‰  unconstr.)']\n",
    "table = []\n",
    "\n",
    "for data_conf in ['nonoise', 'noisy', 'dataset']:\n",
    "    for problem, problem_group in df.loc[df['Data-Config'] == data_conf].groupby('Problem'):\n",
    "\n",
    "        constr_group = None\n",
    "        unconstr_group = None\n",
    "        \n",
    "        for algo_config, constr_group in problem_group.groupby('Algo-Config'):\n",
    "            values = constr_group['Test-R2'].to_numpy()\n",
    "            if algo_config == 'KBP-GP': constr_group = values\n",
    "            else: unconstr_group = values\n",
    "        \n",
    "        stat_gr, pval_gr = ttest_ind(constr_group, unconstr_group, equal_var=False, alternative='greater')\n",
    "        stat_neq, pval_neq = ttest_ind(constr_group, unconstr_group, equal_var=False, alternative='two-sided')\n",
    "        problem_name = problem + problem_name_prefix[data_conf]\n",
    "\n",
    "        table.append([problem_name, pval_gr, pval_neq])\n",
    "\n",
    "pd.DataFrame(table, columns=header).sort_values(by=[''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_group('All', df)\n",
    "#for problem, problem_group in df.groupby('Problem'):\n",
    "#    plot_group(problem, problem_group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
